{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# mass includes\n",
    "import os\n",
    "import rawpy as rp\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## User defined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     11,
     82
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class sonySet(data.Dataset):\n",
    "    def __init__(self, data_root, bk_level, img_size, mode='train'):\n",
    "        self.short_root = os.path.join(data_root, 'Sony', 'short')\n",
    "        self.long_root = os.path.join(data_root, 'Sony', 'long')\n",
    "        self.bk_level = bk_level\n",
    "        self.img_size = img_size\n",
    "        self.mode = mode\n",
    "        with open(os.path.join(data_root, 'Sony_%s_list.txt' % mode),\n",
    "                  'r') as txt:\n",
    "            self.sample_list = txt.read().splitlines()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load a sample\n",
    "        raw, gt, _, _ = self.sample_list[index].split()\n",
    "        raw = raw.split('/')[-1]\n",
    "        gt = gt.split('/')[-1]\n",
    "        ratio = min(float(gt[9:-5]) / float(raw[9:-5]), 300.0)\n",
    "\n",
    "        # read from files\n",
    "        raw_data = rp.imread(os.path.join(self.short_root, raw))\n",
    "        gt_data = rp.imread(os.path.join(self.long_root, gt))\n",
    "        gt_img = gt_data.postprocess(\n",
    "            use_camera_wb=True,\n",
    "            half_size=False,\n",
    "            no_auto_bright=True,\n",
    "            output_bps=16)\n",
    "\n",
    "        # convert flat image to RGBG tensor\n",
    "        raw_flat = raw_data.raw_image_visible.astype(np.float32)\n",
    "        hei, wid = raw_flat.shape\n",
    "        raw_4d = np.stack(\n",
    "            (raw_flat[0:hei:2, 0:wid:2], raw_flat[0:hei:2, 1:wid:2],\n",
    "             raw_flat[1:hei:2, 1:wid:2], raw_flat[1:hei:2, 0:wid:2]),\n",
    "            axis=2)\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            # random crop\n",
    "            crop_h = np.random.randint(0, hei / 2 - self.img_size)\n",
    "            crop_w = np.random.randint(0, wid / 2 - self.img_size)\n",
    "            raw_patch = raw_4d[crop_h:crop_h + self.img_size, crop_w:crop_w +\n",
    "                               self.img_size, :]\n",
    "            gt_patch = gt_img[crop_h * 2:(crop_h + self.img_size) * 2, crop_w *\n",
    "                              2:(crop_w + self.img_size) * 2, :]\n",
    "\n",
    "            # random flip\n",
    "            op = np.random.randint(0, 3)\n",
    "            if op == 0:\n",
    "                # vertical flip\n",
    "                raw_patch = np.flip(raw_patch, axis=0).copy()\n",
    "                gt_patch = np.flip(gt_patch, axis=0).copy()\n",
    "            elif op == 1:\n",
    "                # horizontal flip\n",
    "                raw_patch = np.flip(raw_patch, axis=1).copy()\n",
    "                gt_patch = np.flip(gt_patch, axis=1).copy()\n",
    "\n",
    "            # random transpose\n",
    "            op = np.random.randint(0, 2)\n",
    "            if op == 0:\n",
    "                raw_patch = np.transpose(raw_patch, (1, 0, 2))\n",
    "                gt_patch = np.transpose(gt_patch, (1, 0, 2))\n",
    "        else:\n",
    "            mid_h = int(hei / 4)\n",
    "            mid_w = int(wid / 4)\n",
    "            raw_patch = raw_4d[mid_h:mid_h + self.img_size, mid_w:mid_w +\n",
    "                               self.img_size, :]\n",
    "            gt_patch = gt_img[mid_h * 2:(mid_h + self.img_size) * 2, mid_w *\n",
    "                              2:(mid_w + self.img_size) * 2, :]\n",
    "\n",
    "        # normalize\n",
    "        raw_patch = np.maximum(raw_patch - self.bk_level,\n",
    "                               0) / (16383 - self.bk_level)\n",
    "        gt_patch = np.float32(gt_patch / 65535.0)\n",
    "\n",
    "        # to pyTorch tensor\n",
    "        raw_patch = t.from_numpy(raw_patch)\n",
    "        gt_patch = t.from_numpy(gt_patch)\n",
    "\n",
    "        # amplify raw data and clamp\n",
    "        raw_patch = t.clamp(raw_patch * ratio, 0.0, 1.0)\n",
    "\n",
    "        return raw_patch.permute(2, 0, 1), gt_patch.permute(2, 0, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.sample_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
